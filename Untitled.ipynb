{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "MAX_LENGTH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNNTest(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, embedding_dim, kernel_size, n_layers = 1, max_length=10):\n",
    "        super(CNNTest, self).__init__()\n",
    "\n",
    "        self.num_filters = 16\n",
    "        self.max_length = max_length\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, self.embedding_dim)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(1,self.num_filters,(self.embedding_dim,self.kernel_size),bias=True)\n",
    "        self.conv3 = nn.Conv2d(1,self.num_filters, (self.num_filters, self.kernel_size))\n",
    "        \n",
    "        self.conv_layers = [self.conv2, self.conv3]\n",
    "        \n",
    "        self.n_layers = len(self.conv_layers)\n",
    "        \n",
    "        self.max_pool1d = nn.MaxPool1d(2,stride=2)\n",
    "\n",
    "        self.padding = nn.ZeroPad2d((1,1,1,1))\n",
    "        print(\"product \", self.num_filters*self.max_length/2)\n",
    "        self.linear1 = nn.Linear(int(self.num_filters*int(self.max_length/(2**self.n_layers))),hidden_size,bias=True)\n",
    "\n",
    "        self.convlol = nn.Conv2d(1,3,(self.embedding_dim, self.kernel_size))\n",
    "\n",
    "    def oneLayer(self, input, convLayer):\n",
    "        \n",
    "        out = convLayer(input)\n",
    "        out = F.relu(out)\n",
    "        out = out.transpose(1,2)\n",
    "        out = out.view(1,self.num_filters,-1)\n",
    "        out = self.max_pool1d(out)\n",
    "        out = out.view(1,1,self.num_filters,-1)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def forward(self,input):\n",
    "        input_length = input.size()[0]\n",
    "        embedded = self.embedding(input).view(1,1,self.max_length,-1)\n",
    "        embedded = F.pad(embedded,(0,0,0,1))\n",
    "        embedded = embedded.transpose(2,3)\n",
    "        out = embedded\n",
    "        \n",
    "        for conv in self.conv_layers:\n",
    "            out = self.oneLayer(out,conv)\n",
    "    \n",
    "        out = out.view(1,int(self.num_filters * int(self.max_length/2**self.n_layers)))\n",
    "        out = self.linear1(out)\n",
    "        out = out.view(1,1,-1)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def forward2(self, input):\n",
    "        input_length = input.size()[0]\n",
    "        embedded = self.embedding(input).view(1,1,self.max_length,-1)\n",
    "        embedded = F.pad(embedded,(0,0,0,1))\n",
    "        embedded = embedded.transpose(2,3)\n",
    "        out = embedded\n",
    "        print(\"Input: \", out)\n",
    "        for i in range(self.n_layers):\n",
    "            out = self.conv2(out)\n",
    "            out = F.relu(out)\n",
    "            out = out.transpose(1,2)\n",
    "            out = out.view(1,self.num_filters,-1)\n",
    "            out = self.max_pool1d(out)\n",
    "            out = out.view(1,1,self.num_filters,-1)\n",
    "            print(\"OUT SIZE: \", out.size())\n",
    "            \n",
    "            out2 = self.conv3(out)\n",
    "            out3 = F.relu(out2)\n",
    "            out3 = out3.transpose(1,2)\n",
    "            out3 = out3.view(1,self.num_filters,-1)\n",
    "            out3 = self.max_pool1d(out3)\n",
    "            out3 = out3.view(1,1,self.num_filters,-1)\n",
    "            print(\"out3 size\", out3.size())\n",
    "            #New Layer\n",
    "\n",
    "            #out = self.padding(out)\n",
    "        print(\"HEJ\")\n",
    "        print(\"OUT size\", out.size())\n",
    "        print(\"view size, \", int(self.num_filters * int(MAX_LENGTH/2**2)))\n",
    "              \n",
    "        out3 = out3.view(1,int(self.num_filters * int(MAX_LENGTH/2**2)))\n",
    "        out3 = self.linear1(out3)\n",
    "        out3 = out3.view(1,1,-1)\n",
    "        print(\"OUT3 size\", out3.size())\n",
    "\n",
    "        return out3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 100 sentence pairs\n",
      "Trimmed to 3 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 12\n",
      "eng 7\n",
      "ca va .  /  i m ok .\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import *\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "PAD_token = 2\n",
    "\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"<PAD>\"}\n",
    "        self.n_words = 3  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "# In[41]:\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').        read().strip().split('\\n')\n",
    "\n",
    "    lines = lines[0:100]\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "# In[42]:\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and         len(p[1].split(' ')) < MAX_LENGTH and         p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "\n",
    "# In[49]:\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1,lang2,reverse)\n",
    "    print(\"Read %s sentence pairs\"  % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang,output_lang, pairs = prepareData('eng','fra',True)\n",
    "\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    if(len(indexes) < MAX_LENGTH):\n",
    "        hej = [PAD_token]*(MAX_LENGTH-len(indexes))\n",
    "        indexes = indexes + hej\n",
    "\n",
    "\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_lang, pair[0])\n",
    "    target_variable = variableFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)\n",
    "\n",
    "\n",
    "def print_pair(pair):\n",
    "    print(pair[0], \" / \", pair[1])\n",
    "\n",
    "\n",
    "\n",
    "pair1 = random.choice(pairs)\n",
    "print_pair(pair1)\n",
    "inp, target = variablesFromPair(pair1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX LENGTH 10\n",
      "12\n",
      "input size  10\n",
      "('product ', 80)\n",
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "   0.1620  0.0188 -0.0022  0.2448  0.0009 -0.2193 -0.1214 -0.1328  0.1318\n",
      "\n",
      "Columns 9 to 15 \n",
      "   0.0878 -0.0888  0.0827  0.1779  0.0299 -0.2014 -0.0184\n",
      "[torch.FloatTensor of size 1x1x16]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(pairs)\n",
    "\n",
    "print(\"MAX LENGTH\", MAX_LENGTH)\n",
    "\n",
    "max_length = MAX_LENGTH\n",
    "EMBEDDING_SIZE = 8\n",
    "\n",
    "embedding_dim = 8\n",
    "kernel_size = 2\n",
    "hidden_size = 16\n",
    "\n",
    "print(input_lang.n_words)\n",
    "print(\"input size \", inp.size()[0])\n",
    "\n",
    "cnn_encoder = CNNTest(input_lang.n_words, hidden_size, embedding_dim, kernel_size, max_length)\n",
    "\n",
    "out1 = cnn_encoder(inp)\n",
    "print(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
